{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T19:27:26.159072Z",
     "start_time": "2020-05-02T19:27:25.901980Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  # Disable first GPU\n",
    "  tf.config.set_visible_devices(physical_devices[1:], 'GPU')\n",
    "  logical_devices = tf.config.list_logical_devices('GPU')\n",
    "  # Logical device was not created for first GPU\n",
    "  assert len(logical_devices) == len(physical_devices) - 1\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPU memory too small for model training\n",
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_fun(x):\n",
    "    return tf.image.resize_with_crop_or_pad(x, target_height=640,target_width=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gen(df, directory=os.path.join(os.path.dirname(os.getcwd()), 'ava-data', 'AVA_dataset','images_ext','images')):\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "    return datagen.flow_from_dataframe(df, \n",
    "                                       directory=directory, batch_size=32,\n",
    "                                       x_col='data', y_col='score', class_mode='raw', \n",
    "                                       target_size=(640,640), resizing_function=resize_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T17:00:35.710940Z",
     "start_time": "2020-05-02T17:00:35.485155Z"
    }
   },
   "outputs": [],
   "source": [
    "ava = pd.read_csv('../ava-data/AVA_dataset/AVA.txt', sep=' ', names=['index', 'ID', *['r'+str(x) for x in range(1,11)], 't1', 't2', 'CID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    test_df = pd.read_csv('test_df', index_col=0)\n",
    "except:\n",
    "    test_df = pd.DataFrame(columns=['data', 'score'])\n",
    "    with open('../ava-data/AVA_dataset/aesthetics_image_lists/generic_ss_train.jpgl') as file:\n",
    "        for line in file.readlines():\n",
    "            try:\n",
    "                fID = line.strip()\n",
    "                #print(fID),print(type(fID))\n",
    "                raw_scores = ava.loc[ava.ID == int(fID), 'r1':'r10'].values\n",
    "                score = raw_scores.dot(np.arange(1,11))/raw_scores.sum()\n",
    "                test_df = test_df.append({'data':str(fID)+'.jpg', 'score':np.float32(score[0])}, ignore_index=True)\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_df = pd.read_csv('train_df', index_col=0)\n",
    "except:\n",
    "    train_df = pd.DataFrame(columns=['data', 'score'])\n",
    "    with open('../ava-data/AVA_dataset/aesthetics_image_lists/generic_test.jpgl') as file:\n",
    "        for line in file.readlines():\n",
    "            try:\n",
    "                fID = line.strip()\n",
    "                #print(fID),print(type(fID))\n",
    "                raw_scores = ava.loc[ava.ID == int(fID), 'r1':'r10'].values\n",
    "                score = raw_scores.dot(np.arange(1,11))/raw_scores.sum()\n",
    "                train_df = train_df.append({'data':str(fID)+'.jpg', 'score':np.float32(score[0])}, ignore_index=True)\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19929 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:280: UserWarning: Found 1 invalid image filename(s) in x_col=\"data\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "training_gen = create_gen(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2494 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "val_gen = create_gen(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_batch, label_batch = next(training_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNv2_base = tf.keras.applications.MobileNetV2(input_shape=(640, 640, 3), alpha=1, include_top=False, weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MNv2_base_batch = MNv2_base(im_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNv2_avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "MNv2_avg_pool_batch = MNv2_avg_pool(MNv2_base_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNv2_dense = tf.keras.layers.Dense(1)\n",
    "MNv2_dense_batch = MNv2_dense(MNv2_avg_pool_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNv2_model = tf.keras.models.Sequential([MNv2_base, MNv2_avg_pool, MNv2_dense])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.45\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=623,\n",
    "    decay_rate=0.98,\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule, momentum=0.9)\n",
    "tqdm_callback = tfa.callbacks.TQDMProgressBar()\n",
    "\n",
    "checkpoint_filepath = os.path.join(os.getcwd(), 'checkpoints', 'test',' {epoch:02d}.hdf5')\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNv2_model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      " 8/78 [==>...........................] - ETA: 6:01 - loss: 11962518.6250 - MAE: 3458.6826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 13120. Skipping tag 60219\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 65535 bytes but only got 0. Skipping tag 65535\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5505025 bytes but only got 0. Skipping tag 2360\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 392s 5s/step - loss: 11961500.7051 - MAE: 3458.5361\n"
     ]
    }
   ],
   "source": [
    "loss, MAE = MNv2_model.evaluate(val_gen, steps=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 623 steps, validate for 78 steps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a588d090fd84b409e4287bc03cc5a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=5.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6418dc501c14855a665a345d206869f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=623.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "319/623 [==============>...............] - ETA: 3:34:11 - loss: 2.7261 - MAE: 1.3695"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/623 [=====================>........] - ETA: 1:55:35 - loss: 2.7397 - MAE: 1.3705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 21701 bytes but only got 816. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5176 bytes but only got 816. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622/623 [============================>.] - ETA: 42s - loss: 2.7288 - MAE: 1.3648 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 13120. Skipping tag 60219\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 65535 bytes but only got 0. Skipping tag 65535\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5505025 bytes but only got 0. Skipping tag 2360\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "623/623 [==============================] - 26751s 43s/step - loss: 2.7321 - MAE: 1.3659 - val_loss: 29760.3222 - val_MAE: 172.4595\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6768525319a24552ac179d73d1b28122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=623.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "622/623 [============================>.] - ETA: 42s - loss: 2.5806 - MAE: 1.3194 \n",
      "623/623 [==============================] - 26800s 43s/step - loss: 2.5776 - MAE: 1.3185 - val_loss: 931.2492 - val_MAE: 30.5049\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84596bd271ef49e3849560cb35f4687a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=623.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "622/623 [============================>.] - ETA: 42s - loss: 2.5953 - MAE: 1.3320 \n",
      "623/623 [==============================] - 26864s 43s/step - loss: 2.5931 - MAE: 1.3314 - val_loss: 0.7020 - val_MAE: 0.6697\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40f1c1bc6ea433c88a5acd22a8d8596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=623.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "622/623 [============================>.] - ETA: 42s - loss: 2.6810 - MAE: 1.3370 \n",
      "623/623 [==============================] - 26810s 43s/step - loss: 2.6831 - MAE: 1.3378 - val_loss: 1.3513 - val_MAE: 0.9679\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b995dcac68a48c7a806f53a651f4bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=623.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "622/623 [============================>.] - ETA: 42s - loss: 2.5108 - MAE: 1.3054 \n",
      "623/623 [==============================] - 26762s 43s/step - loss: 2.5079 - MAE: 1.3045 - val_loss: 2.3882 - val_MAE: 1.3729\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ed49a252c8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNv2_model.fit(x=training_gen, epochs=5, validation_data=val_gen, callbacks=[model_checkpoint_callback, tqdm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = optimizer._decayed_lr(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = _58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['MAE'])\n",
    "plt.plot(history.history['val_MAE'])\n",
    "plt.title('model MAE')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.ylim(0,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\foley\\projects\\Mobile-Image-Aesthetics\\checkpoints\\trial\\final\\assets\n"
     ]
    }
   ],
   "source": [
    "MNv2_model.save(os.path.join(os.getcwd(), 'checkpoints', 'trial', 'final'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrupt image error code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 623 steps, validate for 78 steps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24d59573d2949d09e983c514e3499e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=5.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c3af303ffc449c80fd8eee1bef44a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=623.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/623 [==========>...................] - ETA: 4:33:51 - loss: 28477.0915 - MAE: 34.7648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/623 [=========================>....] - ETA: 48:33 - loss: 12296.0367 - MAE: 23.2126\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  TypeError: float() argument must be a string or a number, not 'JpegImageFile'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\", line 975, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 241, in _get_batches_of_transformed_samples\n    x = img_to_array(img, data_format=self.data_format)\n\n  File \"C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 310, in img_to_array\n    x = np.asarray(img, dtype=dtype)\n\n  File \"C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 85, in asarray\n    return array(a, dtype, copy=False, order=order)\n\nTypeError: float() argument must be a string or a number, not 'JpegImageFile'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_distributed_function_19655]\n\nFunction call stack:\ndistributed_function\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-94be2ee4323c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMNv2_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtqdm_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m                       total_epochs=1)\n\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 397\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    769\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    990\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m       \u001b[1;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1009\u001b[0m                   int) or self.epochs_since_last_save >= self.period:\n\u001b[0;32m   1010\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1011\u001b[1;33m       \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_file_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_get_file_path\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     if not self.model._in_multi_worker_mode(\n\u001b[0;32m   1054\u001b[0m     ) or multi_worker_util.should_save_checkpoint():\n\u001b[1;32m-> 1055\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1056\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m       \u001b[1;31m# If this is multi-worker training, and this worker should not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "MNv2_model.fit(x=training_gen, epochs=5, validation_data=val_gen, callbacks=[model_checkpoint_callback, tqdm_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrupt image search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▌                               | 26358/255530 [08:24<58:23, 65.41it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      " 14%|████▋                            | 35815/255530 [11:13<1:04:28, 56.80it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11072 bytes but only got 761. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8134 bytes but only got 761. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 15%|█████                            | 38976/255530 [12:15<1:04:04, 56.33it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 21596 bytes but only got 816. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9108 bytes but only got 816. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 27%|████████▉                        | 68860/255530 [21:09<1:34:19, 32.98it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 19273 bytes but only got 816. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5140 bytes but only got 816. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3144 bytes but only got 816. Skipping tag 34675\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 30%|██████████▋                        | 77736/255530 [23:54<51:53, 57.10it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 262144 bytes but only got 13810. Skipping tag 63626\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 65535 bytes but only got 0. Skipping tag 65535\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5505025 bytes but only got 0. Skipping tag 2360\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 31%|██████████▋                        | 78151/255530 [24:02<52:14, 56.58it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 12255. Skipping tag 582\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 12259. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3715053892 bytes but only got 0. Skipping tag 4567\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n",
      " 31%|██████████▋                        | 78235/255530 [24:03<52:49, 55.94it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 13120. Skipping tag 60219\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 31%|██████████▏                      | 79043/255530 [24:18<1:04:45, 45.43it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11071 bytes but only got 761. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7232 bytes but only got 761. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 32%|███████████                        | 80747/255530 [24:49<58:07, 50.11it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 21721 bytes but only got 816. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5528 bytes but only got 816. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 32%|███████████▎                       | 82245/255530 [25:19<50:06, 57.64it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 22015 bytes but only got 816. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5322 bytes but only got 816. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 33%|███████████▍                       | 83409/255530 [25:40<51:23, 55.81it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 22829 bytes but only got 815. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5072 bytes but only got 815. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1304544 bytes but only got 815. Skipping tag 37724\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 33%|███████████▍                       | 83713/255530 [25:45<58:40, 48.80it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 22466 bytes but only got 803. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5876 bytes but only got 803. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 44%|██████████████▉                   | 112149/255530 [35:32<48:27, 49.32it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 21652 bytes but only got 848. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 4898 bytes but only got 848. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 940 bytes but only got 848. Skipping tag 34675\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████▉                 | 127031/255530 [40:09<35:07, 60.96it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 22149 bytes but only got 816. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5874 bytes but only got 816. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 54%|██████████████████▍               | 138197/255530 [43:25<36:14, 53.96it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18481152 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 33619968 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 31197188 bytes but only got 0. Skipping tag 1029\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 4. \n",
      "  warnings.warn(str(msg))\n",
      " 60%|████████████████████▎             | 152951/255530 [47:52<27:59, 61.09it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 21701 bytes but only got 816. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5176 bytes but only got 816. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 73%|████████████████████████▉         | 187224/255530 [58:14<21:06, 53.93it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 21566 bytes but only got 816. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6982 bytes but only got 816. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 75%|█████████████████████████▎        | 190528/255530 [59:11<19:05, 56.73it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8058 bytes but only got 816. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 75%|█████████████████████████▌        | 192355/255530 [59:40<19:00, 55.39it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 211288080 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 10470. Skipping tag 582\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 10474. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 5. \n",
      "  warnings.warn(str(msg))\n",
      " 77%|████████████████████████▌       | 196563/255530 [1:00:57<16:01, 61.32it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 22046 bytes but only got 816. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6690 bytes but only got 816. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      " 83%|██████████████████████████▌     | 212435/255530 [1:05:28<16:09, 44.45it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1572864 bytes but only got 0. Skipping tag 42\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 4568514560 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 19600506880 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2684485632 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2751528960 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6881280 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2490368 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 13631488 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 967680 bytes but only got 0. Skipping tag 62720\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 983040 bytes but only got 14026. Skipping tag 40960\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3942907908 bytes but only got 14024. Skipping tag 2304\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1048592 bytes but only got 14022. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 134219776 bytes but only got 14026. Skipping tag 39756\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6291568 bytes but only got 0. Skipping tag 159\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 34079240 bytes but only got 13766. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 63047442 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 109908 bytes but only got 0. Skipping tag 48197\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 65536 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 285413634 bytes but only got 0. Skipping tag 780\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████▍ | 242651/255530 [1:14:31<03:39, 58.64it/s]C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11046 bytes but only got 749. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\foley\\anaconda3\\envs\\tensorflow2PC\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9664 bytes but only got 749. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "100%|████████████████████████████████| 255530/255530 [1:18:26<00:00, 54.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "missing_list = []\n",
    "error_list1 = []\n",
    "error_list2 = []\n",
    "path = os.path.join(os.path.dirname(os.getcwd()), 'ava-data', 'AVA_dataset','images_ext','images')\n",
    "for image in tqdm(ava.ID):\n",
    "    img_path = os.path.join(path, str(image) + '.jpg')\n",
    "    \n",
    "    cv_img = cv2.imread(img_path)\n",
    "    \n",
    "    if cv_img is None:\n",
    "        missing_list.append(image)\n",
    "        continue\n",
    "    try:\n",
    "        shape = cv_img.shape\n",
    "    except:\n",
    "        error_list1.append(img_path)\n",
    "    try:\n",
    "        sk_img = io.imread(img_path)\n",
    "        shape = sk_img.shape\n",
    "    except:\n",
    "        cv2.imwrite(img_path, cv_img)\n",
    "        error_list2.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_df = pd.DataFrame(columns=['ID', 'miss', 'corr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                  | 8395/255530 [00:52<41:32, 99.14it/s]"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "path = os.path.join(os.path.dirname(os.getcwd()), 'ava-data', 'AVA_dataset','images_ext','images')\n",
    "for image in tqdm(ava.ID):\n",
    "    try:\n",
    "        try:\n",
    "            im = Image.open(os.path.join(path, str(image)+'.jpg'))\n",
    "        except:\n",
    "            corrupt_df = corrupt_df.append({'ID': image, 'miss':True, 'corr':False}, ignore_index=True)\n",
    "            continue\n",
    "        im.getdata()\n",
    "    except:\n",
    "        corrupt_df = corrupt_df.append({'ID': image, 'miss':False, 'corr':True}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>miss</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>953619</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>953958</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>954184</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>954113</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>953980</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>954175</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>953349</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>953645</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>953897</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>953841</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>310261</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>848725</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>444892</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>567829</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>398594</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>638163</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>397289</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>104855</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11066</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>148477</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>52365</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>430454</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  miss   corr\n",
       "0   953619  True  False\n",
       "1   953958  True  False\n",
       "2   954184  True  False\n",
       "3   954113  True  False\n",
       "4   953980  True  False\n",
       "5   954175  True  False\n",
       "6   953349  True  False\n",
       "7   953645  True  False\n",
       "8   953897  True  False\n",
       "9   953841  True  False\n",
       "10  310261  True  False\n",
       "11  848725  True  False\n",
       "12  444892  True  False\n",
       "13  567829  True  False\n",
       "14  398594  True  False\n",
       "15  638163  True  False\n",
       "16  397289  True  False\n",
       "17  104855  True  False\n",
       "18   11066  True  False\n",
       "19  148477  True  False\n",
       "20   52365  True  False\n",
       "21  430454  True  False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307200, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = Image.open(os.path.join(path, str(724198)+'.jpg'))\n",
    "np.array(im.getdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2PC",
   "language": "python",
   "name": "tensorflow2pc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
